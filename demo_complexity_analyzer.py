#!/usr/bin/env python3
"""
ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨æ¼”ç¤º

å±•ç¤ºå¤šç»´åº¦ä»»åŠ¡å¤æ‚åº¦è¯„ä¼°åŠŸèƒ½çš„å®é™…åº”ç”¨
"""

import asyncio
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from src.intelligence.task_complexity_analyzer import TaskComplexityAnalyzer, ComplexityLevel
from src.config.model_config import create_model_client


async def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤º"""
    print("ğŸ¯ ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨ - äº¤äº’å¼æ¼”ç¤º")
    print("=" * 60)
    print("è¯·è¾“å…¥æ‚¨çš„ä»»åŠ¡æè¿°ï¼Œæˆ‘å°†ä¸ºæ‚¨åˆ†æå…¶å¤æ‚åº¦")
    print("è¾“å…¥ 'quit' é€€å‡ºç¨‹åº")
    print()
    
    # åˆ›å»ºåˆ†æå™¨
    try:
        model_client = create_model_client()
        analyzer = TaskComplexityAnalyzer(model_client)
        print("âœ… LLMå¢å¼ºåˆ†æå™¨å·²å¯åŠ¨")
    except:
        analyzer = TaskComplexityAnalyzer()
        print("âš ï¸ ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æå™¨ï¼ˆæ— LLMï¼‰")
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            task_description = input("\nğŸ“ è¯·è¾“å…¥ä»»åŠ¡æè¿°: ").strip()
            
            if task_description.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            if not task_description:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ä»»åŠ¡æè¿°")
                continue
            
            print("\nğŸ” æ­£åœ¨åˆ†æ...")
            
            # åˆ†æå¤æ‚åº¦
            metrics = await analyzer.analyze_complexity(task_description)
            summary = analyzer.get_complexity_summary(metrics)
            
            # æ˜¾ç¤ºç»“æœ
            print("\nğŸ“Š åˆ†æç»“æœ:")
            print("-" * 40)
            print(f"ğŸ¯ å¤æ‚åº¦ç­‰çº§: {summary['complexity_level'].upper()}")
            print(f"ğŸ“ˆ å¤æ‚åº¦åˆ†æ•°: {summary['overall_complexity']:.3f}")
            print(f"ğŸ² ç½®ä¿¡åº¦: {summary['confidence_score']:.3f}")
            
            print(f"\nâ±ï¸ é¢„ä¼°å·¥ä½œé‡:")
            effort = summary['estimated_effort']
            print(f"  å¼€å‘æ—¶é—´: {effort['development_time']}")
            print(f"  æµ‹è¯•æ—¶é—´: {effort['testing_time']}")
            print(f"  æ€»ä½“å·¥ä½œé‡: {effort['total_effort']}")
            
            print(f"\nğŸ”§ æ¨èæ–¹æ³•:")
            for rec in summary['recommended_approach']:
                print(f"  â€¢ {rec}")
            
            print(f"\nâš ï¸ å…³é”®æŒ‘æˆ˜:")
            for challenge in summary['key_challenges']:
                print(f"  â€¢ {challenge}")
            
            # æ˜¾ç¤ºè¯¦ç»†åˆ†è§£
            breakdown = summary['breakdown']
            print(f"\nğŸ“‹ è¯¦ç»†åˆ†è§£:")
            print(f"  åŸºç¡€æŒ‡æ ‡: {breakdown['basic_metrics']['functions']}ä¸ªå‡½æ•°, "
                  f"{breakdown['basic_metrics']['classes']}ä¸ªç±», "
                  f"çº¦{breakdown['basic_metrics']['lines_of_code']}è¡Œä»£ç ")
            
            tech = breakdown['technical_complexity']
            print(f"  æŠ€æœ¯å¤æ‚åº¦: ç®—æ³•({tech['algorithm']:.2f}), "
                  f"æ•°æ®ç»“æ„({tech['data_structure']:.2f}), "
                  f"é›†æˆ({tech['integration']:.2f})")
            
            if breakdown['llm_evaluation']['cognitive_load'] > 0:
                llm = breakdown['llm_evaluation']
                print(f"  LLMè¯„ä¼°: è®¤çŸ¥è´Ÿè·({llm['cognitive_load']:.2f}), "
                      f"å®ç°éš¾åº¦({llm['implementation_difficulty']:.2f}), "
                      f"æµ‹è¯•å¤æ‚åº¦({llm['testing_complexity']:.2f})")
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
            break
        except Exception as e:
            print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
    
    # æ¸…ç†èµ„æº
    if hasattr(analyzer, 'model_client') and analyzer.model_client:
        await analyzer.model_client.close()


async def preset_demo():
    """é¢„è®¾ç¤ºä¾‹æ¼”ç¤º"""
    print("ğŸ¯ ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨ - é¢„è®¾ç¤ºä¾‹æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºåˆ†æå™¨
    try:
        model_client = create_model_client()
        analyzer = TaskComplexityAnalyzer(model_client)
        print("âœ… LLMå¢å¼ºåˆ†æå™¨å·²å¯åŠ¨\n")
    except:
        analyzer = TaskComplexityAnalyzer()
        print("âš ï¸ ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æå™¨ï¼ˆæ— LLMï¼‰\n")
    
    # é¢„è®¾ç¤ºä¾‹
    examples = [
        {
            "name": "ç®€å•å·¥å…·",
            "description": "åˆ›å»ºä¸€ä¸ªå¯†ç ç”Ÿæˆå™¨ï¼Œå¯ä»¥ç”ŸæˆæŒ‡å®šé•¿åº¦çš„éšæœºå¯†ç ",
            "expected": "simple"
        },
        {
            "name": "ä¸­ç­‰ç³»ç»Ÿ",
            "description": "å¼€å‘ä¸€ä¸ªåœ¨çº¿å›¾ä¹¦ç®¡ç†ç³»ç»Ÿï¼ŒåŒ…å«å›¾ä¹¦å¢åˆ æ”¹æŸ¥ã€ç”¨æˆ·ç®¡ç†ã€å€Ÿé˜…è®°å½•ã€æœç´¢åŠŸèƒ½",
            "expected": "moderate"
        },
        {
            "name": "å¤æ‚å¹³å°",
            "description": "æ„å»ºä¸€ä¸ªå®æ—¶æ•°æ®åˆ†æå¹³å°ï¼Œæ”¯æŒå¤šç§æ•°æ®æºæ¥å…¥ã€æµå¼å¤„ç†ã€æœºå™¨å­¦ä¹ é¢„æµ‹ã€å¯è§†åŒ–å±•ç¤º",
            "expected": "complex"
        },
        {
            "name": "æå¤æ‚ç³»ç»Ÿ",
            "description": "å¼€å‘ä¸€ä¸ªè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿï¼ŒåŒ…å«è®¡ç®—æœºè§†è§‰ã€æ·±åº¦å­¦ä¹ ã€è·¯å¾„è§„åˆ’ã€å†³ç­–æ§åˆ¶ã€å®‰å…¨ç›‘æ§",
            "expected": "very_complex"
        }
    ]
    
    for i, example in enumerate(examples, 1):
        print(f"ğŸ“‹ ç¤ºä¾‹ {i}: {example['name']}")
        print(f"æè¿°: {example['description']}")
        print(f"é¢„æœŸå¤æ‚åº¦: {example['expected']}")
        
        # åˆ†æå¤æ‚åº¦
        metrics = await analyzer.analyze_complexity(example['description'])
        summary = analyzer.get_complexity_summary(metrics)
        
        # æ˜¾ç¤ºç»“æœ
        actual = summary['complexity_level']
        score = summary['overall_complexity']
        confidence = summary['confidence_score']
        
        status = "âœ… ç¬¦åˆé¢„æœŸ" if actual == example['expected'] else "âŒ ä¸ç¬¦åˆé¢„æœŸ"
        print(f"åˆ†æç»“æœ: {actual} (åˆ†æ•°: {score:.3f}, ç½®ä¿¡åº¦: {confidence:.3f}) {status}")
        
        # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
        effort = summary['estimated_effort']['total_effort']
        challenges = summary['key_challenges'][:2]  # åªæ˜¾ç¤ºå‰2ä¸ªæŒ‘æˆ˜
        
        print(f"å·¥ä½œé‡: {effort}, ä¸»è¦æŒ‘æˆ˜: {', '.join(challenges)}")
        print("-" * 60)
    
    # æ¸…ç†èµ„æº
    if hasattr(analyzer, 'model_client') and analyzer.model_client:
        await analyzer.model_client.close()


async def comparison_demo():
    """å¯¹æ¯”æ¼”ç¤ºï¼šæœ‰LLM vs æ— LLM"""
    print("ğŸ¯ ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨ - å¯¹æ¯”æ¼”ç¤º")
    print("=" * 60)
    
    test_task = "å¼€å‘ä¸€ä¸ªåŸºäºå¾®æœåŠ¡æ¶æ„çš„ç”µå•†å¹³å°ï¼ŒåŒ…å«ç”¨æˆ·æœåŠ¡ã€å•†å“æœåŠ¡ã€è®¢å•æœåŠ¡ã€æ”¯ä»˜æœåŠ¡ã€æ¨èç³»ç»Ÿ"
    
    print(f"æµ‹è¯•ä»»åŠ¡: {test_task}\n")
    
    # æ— LLMåˆ†æ
    print("ğŸ”§ åŸºç¡€è§„åˆ™åˆ†æå™¨:")
    basic_analyzer = TaskComplexityAnalyzer()
    basic_metrics = await basic_analyzer.analyze_complexity(test_task)
    basic_summary = basic_analyzer.get_complexity_summary(basic_metrics)
    
    print(f"  å¤æ‚åº¦: {basic_summary['complexity_level']} (åˆ†æ•°: {basic_summary['overall_complexity']:.3f})")
    print(f"  ç½®ä¿¡åº¦: {basic_summary['confidence_score']:.3f}")
    print(f"  å·¥ä½œé‡: {basic_summary['estimated_effort']['total_effort']}")
    
    # æœ‰LLMåˆ†æ
    try:
        print("\nğŸ¤– LLMå¢å¼ºåˆ†æå™¨:")
        model_client = create_model_client()
        llm_analyzer = TaskComplexityAnalyzer(model_client)
        llm_metrics = await llm_analyzer.analyze_complexity(test_task)
        llm_summary = llm_analyzer.get_complexity_summary(llm_metrics)
        
        print(f"  å¤æ‚åº¦: {llm_summary['complexity_level']} (åˆ†æ•°: {llm_summary['overall_complexity']:.3f})")
        print(f"  ç½®ä¿¡åº¦: {llm_summary['confidence_score']:.3f}")
        print(f"  å·¥ä½œé‡: {llm_summary['estimated_effort']['total_effort']}")
        
        # æ˜¾ç¤ºLLMç‰¹æœ‰çš„è¯„ä¼°
        llm_eval = llm_summary['breakdown']['llm_evaluation']
        print(f"  LLMè¯„ä¼°: è®¤çŸ¥è´Ÿè·({llm_eval['cognitive_load']:.2f}), "
              f"å®ç°éš¾åº¦({llm_eval['implementation_difficulty']:.2f}), "
              f"æµ‹è¯•å¤æ‚åº¦({llm_eval['testing_complexity']:.2f})")
        
        await model_client.close()
        
    except Exception as e:
        print(f"  âŒ LLMåˆ†æå¤±è´¥: {e}")
    
    print("\nğŸ“Š å¯¹æ¯”æ€»ç»“:")
    print("  â€¢ åŸºç¡€åˆ†æå™¨ï¼šå¿«é€Ÿã€ç¨³å®šï¼Œä½†å‡†ç¡®æ€§æœ‰é™")
    print("  â€¢ LLMå¢å¼ºåˆ†æå™¨ï¼šæ›´å‡†ç¡®ã€æ›´æ™ºèƒ½ï¼Œä½†éœ€è¦APIæ”¯æŒ")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨æ¼”ç¤ºç¨‹åº")
    print("=" * 80)
    
    while True:
        print("\nè¯·é€‰æ‹©æ¼”ç¤ºæ¨¡å¼:")
        print("1. äº¤äº’å¼æ¼”ç¤º - è¾“å…¥è‡ªå®šä¹‰ä»»åŠ¡")
        print("2. é¢„è®¾ç¤ºä¾‹æ¼”ç¤º - æŸ¥çœ‹å…¸å‹æ¡ˆä¾‹")
        print("3. å¯¹æ¯”æ¼”ç¤º - åŸºç¡€ vs LLMå¢å¼º")
        print("4. é€€å‡ºç¨‹åº")
        
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
            
            if choice == "1":
                await interactive_demo()
            elif choice == "2":
                await preset_demo()
            elif choice == "3":
                await comparison_demo()
            elif choice == "4":
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-4")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
            break
        except Exception as e:
            print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")


if __name__ == "__main__":
    asyncio.run(main())
