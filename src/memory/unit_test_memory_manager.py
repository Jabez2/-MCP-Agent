"""
UnitTestAgentä¸“ç”¨Memoryç®¡ç†å™¨

ä¸ºUnitTestAgentæä¾›å®Œæ•´çš„æµ‹è¯•è¾“å‡ºä¿å­˜å’Œæ£€ç´¢åŠŸèƒ½ï¼Œ
ç¡®ä¿RefactoringAgentèƒ½å¤Ÿè·å–åˆ°è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
"""

import asyncio
import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path

from autogen_core.memory import MemoryContent, MemoryMimeType
from .memory_config import memory_config
from .base_memory_manager import execution_log_manager


class UnitTestMemoryManager:
    """UnitTestAgentä¸“ç”¨Memoryç®¡ç†å™¨"""
    
    def __init__(self):
        self.execution_log_manager = execution_log_manager
        self.test_memory = None
        self._initialized = False
        
        # æµ‹è¯•ç»“æœç¼“å­˜
        self.latest_test_results = {}
        self.test_history = []
    
    async def initialize(self):
        """åˆå§‹åŒ–UnitTest Memoryç³»ç»Ÿ"""
        if not self._initialized:
            self.test_memory = memory_config.create_workflow_memory()
            self._initialized = True
            print("ğŸ§ª UnitTestä¸“ç”¨Memoryç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # ================================
    # å®Œæ•´æµ‹è¯•è¾“å‡ºä¿å­˜
    # ================================
    
    async def record_complete_test_execution(self,
                                           agent_name: str,
                                           task_description: str,
                                           raw_output: str,
                                           execution_result: Dict[str, Any],
                                           success: bool,
                                           duration: float,
                                           test_files: List[str] = None,
                                           test_reports: Dict[str, Any] = None):
        """è®°å½•å®Œæ•´çš„æµ‹è¯•æ‰§è¡Œä¿¡æ¯"""
        if not self._initialized:
            await self.initialize()
        
        timestamp = datetime.now().isoformat()
        
        # è§£ææµ‹è¯•è¾“å‡º
        parsed_output = self._parse_test_output(raw_output)
        
        # æ„å»ºå®Œæ•´çš„æµ‹è¯•è®°å½•
        complete_test_record = {
            "agent_name": agent_name,
            "task_description": task_description,
            "timestamp": timestamp,
            "success": success,
            "duration": duration,
            "raw_output": raw_output,
            "parsed_output": parsed_output,
            "execution_result": execution_result,
            "test_files": test_files or [],
            "test_reports": test_reports or {},
            "analysis": self._analyze_test_results(parsed_output, success)
        }
        
        # æ›´æ–°ç¼“å­˜
        self.latest_test_results[agent_name] = complete_test_record
        self.test_history.append(complete_test_record)
        
        # ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        await self._store_complete_test_record(complete_test_record)
        
        print(f"ğŸ§ª å®Œæ•´æµ‹è¯•è®°å½•å·²ä¿å­˜: {agent_name} - {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        return complete_test_record
    
    def _parse_test_output(self, raw_output: str) -> Dict[str, Any]:
        """è§£ææµ‹è¯•è¾“å‡ºï¼Œæå–å…³é”®ä¿¡æ¯"""
        parsed = {
            "test_summary": {},
            "failures": [],
            "errors": [],
            "passed_tests": [],
            "test_files_executed": [],
            "execution_details": []
        }
        
        lines = raw_output.split('\n')
        current_section = None
        current_failure = {}
        
        for line in lines:
            line = line.strip()
            
            # è§£ææµ‹è¯•æ‘˜è¦
            if "tests run" in line.lower() or "ran " in line.lower():
                # æå–æµ‹è¯•æ•°é‡ä¿¡æ¯
                numbers = re.findall(r'\d+', line)
                if numbers:
                    parsed["test_summary"]["total_tests"] = int(numbers[0]) if numbers else 0
            
            # è§£æå¤±è´¥ä¿¡æ¯
            if line.startswith("FAIL:") or line.startswith("ERROR:"):
                if current_failure:
                    if current_section == "failure":
                        parsed["failures"].append(current_failure)
                    elif current_section == "error":
                        parsed["errors"].append(current_failure)
                
                current_failure = {
                    "test_name": line.split(":", 1)[1].strip() if ":" in line else line,
                    "type": "FAIL" if line.startswith("FAIL:") else "ERROR",
                    "details": []
                }
                current_section = "failure" if line.startswith("FAIL:") else "error"
            
            # æ”¶é›†å¤±è´¥è¯¦æƒ…
            elif current_section in ["failure", "error"] and line:
                if line.startswith("AssertionError") or line.startswith("Traceback") or "File " in line:
                    current_failure["details"].append(line)
            
            # è§£æé€šè¿‡çš„æµ‹è¯•
            elif "ok" in line.lower() and "test" in line.lower():
                parsed["passed_tests"].append(line)
            
            # è§£ææ‰§è¡Œçš„æµ‹è¯•æ–‡ä»¶
            elif line.startswith("ğŸ§ª æ‰§è¡Œæµ‹è¯•æ–‡ä»¶:") or "test_" in line and ".py" in line:
                parsed["test_files_executed"].append(line)
            
            # æ”¶é›†æ‰§è¡Œè¯¦æƒ…
            elif line.startswith("ğŸ“Š") or line.startswith("âœ…") or line.startswith("âŒ"):
                parsed["execution_details"].append(line)
        
        # å¤„ç†æœ€åä¸€ä¸ªå¤±è´¥è®°å½•
        if current_failure:
            if current_section == "failure":
                parsed["failures"].append(current_failure)
            elif current_section == "error":
                parsed["errors"].append(current_failure)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        parsed["test_summary"].update({
            "failures_count": len(parsed["failures"]),
            "errors_count": len(parsed["errors"]),
            "passed_count": len(parsed["passed_tests"]),
            "files_executed": len(parsed["test_files_executed"])
        })
        
        return parsed
    
    def _analyze_test_results(self, parsed_output: Dict[str, Any], success: bool) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•ç»“æœï¼Œç”Ÿæˆæ™ºèƒ½åˆ†æ"""
        analysis = {
            "overall_status": "PASSED" if success else "FAILED",
            "key_issues": [],
            "recommendations": [],
            "error_patterns": [],
            "fix_suggestions": []
        }
        
        # åˆ†æå¤±è´¥æ¨¡å¼
        for failure in parsed_output.get("failures", []):
            issue = {
                "type": "test_failure",
                "test": failure.get("test_name", ""),
                "details": failure.get("details", [])
            }
            analysis["key_issues"].append(issue)
            
            # åˆ†æé”™è¯¯æ¨¡å¼
            details_text = " ".join(failure.get("details", []))
            if "AssertionError" in details_text:
                analysis["error_patterns"].append("assertion_error")
                if "Expected" in details_text and "but got" in details_text:
                    analysis["fix_suggestions"].append("æ£€æŸ¥å‡½æ•°è¿”å›å€¼æ ¼å¼")
            elif "ImportError" in details_text or "ModuleNotFoundError" in details_text:
                analysis["error_patterns"].append("import_error")
                analysis["fix_suggestions"].append("æ£€æŸ¥æ¨¡å—å¯¼å…¥è·¯å¾„")
            elif "AttributeError" in details_text:
                analysis["error_patterns"].append("attribute_error")
                analysis["fix_suggestions"].append("æ£€æŸ¥å‡½æ•°æˆ–å±æ€§åç§°")
        
        # åˆ†æé”™è¯¯
        for error in parsed_output.get("errors", []):
            issue = {
                "type": "test_error",
                "test": error.get("test_name", ""),
                "details": error.get("details", [])
            }
            analysis["key_issues"].append(issue)
        
        # ç”Ÿæˆå»ºè®®
        if not success:
            if analysis["error_patterns"]:
                analysis["recommendations"].append("é‡ç‚¹å…³æ³¨ä»¥ä¸‹é”™è¯¯æ¨¡å¼: " + ", ".join(set(analysis["error_patterns"])))
            
            if "assertion_error" in analysis["error_patterns"]:
                analysis["recommendations"].append("æ£€æŸ¥ä¸šåŠ¡é€»è¾‘å®ç°æ˜¯å¦ç¬¦åˆæµ‹è¯•æœŸæœ›")
            
            if "import_error" in analysis["error_patterns"]:
                analysis["recommendations"].append("æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæ¨¡å—ç»“æ„")
        else:
            analysis["recommendations"].append("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œä»£ç è´¨é‡è‰¯å¥½")
        
        return analysis
    
    # ================================
    # ä¸ºRefactoringAgentæä¾›è¯¦ç»†ä¿¡æ¯
    # ================================
    
    async def get_detailed_test_info_for_refactoring(self, agent_name: str = "UnitTestAgent") -> Dict[str, Any]:
        """ä¸ºRefactoringAgentæä¾›è¯¦ç»†çš„æµ‹è¯•ä¿¡æ¯"""
        if agent_name in self.latest_test_results:
            test_record = self.latest_test_results[agent_name]
            
            # æ„å»ºRefactoringAgentéœ€è¦çš„è¯¦ç»†ä¿¡æ¯
            refactoring_info = {
                "test_execution_summary": {
                    "success": test_record["success"],
                    "duration": test_record["duration"],
                    "timestamp": test_record["timestamp"]
                },
                "complete_raw_output": test_record["raw_output"],
                "parsed_failures": test_record["parsed_output"].get("failures", []),
                "parsed_errors": test_record["parsed_output"].get("errors", []),
                "test_files": test_record["test_files"],
                "analysis": test_record["analysis"],
                "fix_suggestions": test_record["analysis"].get("fix_suggestions", []),
                "error_patterns": test_record["analysis"].get("error_patterns", []),
                "detailed_recommendations": self._generate_detailed_recommendations(test_record)
            }
            
            return refactoring_info
        
        return {}
    
    def _generate_detailed_recommendations(self, test_record: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆè¯¦ç»†çš„ä¿®å¤å»ºè®®"""
        recommendations = []
        parsed_output = test_record["parsed_output"]
        
        # åŸºäºå¤±è´¥ä¿¡æ¯ç”Ÿæˆå…·ä½“å»ºè®®
        for failure in parsed_output.get("failures", []):
            test_name = failure.get("test_name", "")
            details = " ".join(failure.get("details", []))
            
            if "AssertionError" in details:
                if "Expected" in details and "but got" in details:
                    # æå–æœŸæœ›å€¼å’Œå®é™…å€¼
                    expected_match = re.search(r"Expected[:\s]+['\"]([^'\"]+)['\"]", details)
                    got_match = re.search(r"but got[:\s]+['\"]([^'\"]+)['\"]", details)
                    
                    if expected_match and got_match:
                        expected = expected_match.group(1)
                        got = got_match.group(1)
                        recommendations.append(f"æµ‹è¯• {test_name}: æœŸæœ›è¿”å› '{expected}'ï¼Œå®é™…è¿”å› '{got}'ï¼Œè¯·æ£€æŸ¥å‡½æ•°å®ç°")
                    else:
                        recommendations.append(f"æµ‹è¯• {test_name}: æ–­è¨€å¤±è´¥ï¼Œè¯·æ£€æŸ¥å‡½æ•°è¿”å›å€¼")
                else:
                    recommendations.append(f"æµ‹è¯• {test_name}: æ–­è¨€é”™è¯¯ï¼Œè¯·æ£€æŸ¥æµ‹è¯•é€»è¾‘")
            
            elif "ImportError" in details or "ModuleNotFoundError" in details:
                recommendations.append(f"æµ‹è¯• {test_name}: æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæ¨¡å—ç»“æ„")
            
            elif "AttributeError" in details:
                recommendations.append(f"æµ‹è¯• {test_name}: å±æ€§é”™è¯¯ï¼Œè¯·æ£€æŸ¥å‡½æ•°åç§°æˆ–ç±»å±æ€§")
        
        return recommendations
    
    async def get_test_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æµ‹è¯•å†å²è®°å½•"""
        return self.test_history[-limit:] if self.test_history else []
    
    # ================================
    # å†…éƒ¨å­˜å‚¨æ–¹æ³•
    # ================================
    
    async def _store_complete_test_record(self, test_record: Dict[str, Any]):
        """å°†å®Œæ•´æµ‹è¯•è®°å½•å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“"""
        if not self._initialized:
            await self.initialize()
        
        # æ„å»ºå­˜å‚¨å†…å®¹
        content = f"""
UnitTest Complete Record: {test_record['agent_name']}
Task: {test_record['task_description']}
Timestamp: {test_record['timestamp']}
Success: {test_record['success']}
Duration: {test_record['duration']}s

=== RAW OUTPUT ===
{test_record['raw_output']}

=== PARSED ANALYSIS ===
Test Summary: {json.dumps(test_record['parsed_output']['test_summary'], ensure_ascii=False)}
Failures: {len(test_record['parsed_output']['failures'])}
Errors: {len(test_record['parsed_output']['errors'])}

=== FAILURE DETAILS ===
{json.dumps(test_record['parsed_output']['failures'], indent=2, ensure_ascii=False)}

=== ERROR DETAILS ===
{json.dumps(test_record['parsed_output']['errors'], indent=2, ensure_ascii=False)}

=== INTELLIGENT ANALYSIS ===
{json.dumps(test_record['analysis'], indent=2, ensure_ascii=False)}
        """.strip()
        
        await self.test_memory.add(
            MemoryContent(
                content=content,
                mime_type=MemoryMimeType.TEXT,
                metadata={
                    "type": "complete_unit_test",
                    "agent_name": test_record['agent_name'],
                    "success": test_record['success'],
                    "timestamp": test_record['timestamp'],
                    "duration": test_record['duration'],
                    "failures_count": len(test_record['parsed_output']['failures']),
                    "errors_count": len(test_record['parsed_output']['errors']),
                    "test_files_count": len(test_record['test_files'])
                }
            )
        )
    
    async def close(self):
        """å…³é—­UnitTest Memoryè¿æ¥"""
        if self.test_memory:
            await self.test_memory.close()


# å…¨å±€å®ä¾‹
unit_test_memory_manager = UnitTestMemoryManager()
