"""
æ ¸å¿ƒç¼–æ’å™¨ç±»

é«˜çº§å›¾æµç¨‹ç¼–æ’å™¨ - ç»“åˆ GraphFlow å’Œ MagenticOne çš„æ™ºèƒ½è°ƒåº¦
è´Ÿè´£ä»»åŠ¡åˆ†è§£ã€æ™ºèƒ½æ‰§è¡Œã€ç›‘æ§å’Œé”™è¯¯å¤„ç†ã€‚
"""

import asyncio
import json
import time
from typing import Any, Dict, List, Optional, Set, Sequence
from autogen_agentchat.base import ChatAgent, Response
from autogen_agentchat.messages import TextMessage, StopMessage
from autogen_core.models import UserMessage

from .data_structures import NodeState, TaskLedger, ProgressLedger
from .orchestrator_helpers import OrchestratorHelpers
from ..utils.file_naming import parse_task_and_generate_config
from ..utils.workflow_logger import WorkflowLogger
from ..memory import (
    execution_log_manager,
    agent_state_manager,
    agent_communication_memory,
    initialize_memory_system,
    cleanup_memory_system
)
from ..memory.unit_test_memory_manager import unit_test_memory_manager


class GraphFlowOrchestrator:
    """
    é«˜çº§å›¾æµç¨‹ç¼–æ’å™¨ - ç»“åˆ GraphFlow å’Œ MagenticOne çš„æ™ºèƒ½è°ƒåº¦

    è¿™ä¸ªç±»è´Ÿè´£ï¼š
    1. ä»»åŠ¡åˆ†è§£å’Œè®¡åˆ’åˆ¶å®šï¼ˆå¤–å±‚å¾ªç¯ï¼‰
    2. æ™ºèƒ½æ‰§è¡Œå’Œç›‘æ§ï¼ˆå†…å±‚å¾ªç¯ï¼‰
    3. èŠ‚ç‚¹é€‰æ‹©å’ŒçŠ¶æ€ç®¡ç†
    4. æ‰§è¡Œç»“æœåˆ†æå’Œé”™è¯¯å¤„ç†
    """

    def __init__(self, graph, participants: List[ChatAgent], model_client, max_stalls: int = 3, max_retries: int = 2):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨

        Args:
            graph: æ‰§è¡Œå›¾ç»“æ„
            participants: å‚ä¸çš„Agentåˆ—è¡¨
            model_client: LLMæ¨¡å‹å®¢æˆ·ç«¯
            max_stalls: æœ€å¤§åœæ»æ¬¡æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.graph = graph
        self.participants = {agent.name: agent for agent in participants}
        self.model_client = model_client
        self.max_stalls = max_stalls
        self.max_retries = max_retries

        # MagenticOne é£æ ¼çš„çŠ¶æ€ç®¡ç†
        self.task_ledger = TaskLedger()
        self.progress_ledger = ProgressLedger()

        # æ™ºèƒ½è·¯å¾„è§£æå™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.path_resolver = None

        # å·¥ä½œæµæ—¥å¿—è®°å½•å™¨
        self.workflow_logger = WorkflowLogger()

        # Memoryç³»ç»Ÿæ ‡å¿—
        self.memory_initialized = False

        # åˆå§‹åŒ–èŠ‚ç‚¹çŠ¶æ€
        for node_name in self.participants.keys():
            self.progress_ledger.node_states[node_name] = NodeState.NOT_STARTED

        # åˆ†æ Agent èƒ½åŠ›
        self._analyze_agent_capabilities()

    def _analyze_agent_capabilities(self):
        """åˆ†æå¹¶è®°å½•æ¯ä¸ªAgentçš„èƒ½åŠ›æè¿°"""
        for name, agent in self.participants.items():
            self.task_ledger.agent_capabilities[name] = agent.description

    async def _initialize_memory_system(self):
        """åˆå§‹åŒ–Memoryç³»ç»Ÿ"""
        if not self.memory_initialized:
            success = await initialize_memory_system()
            if success:
                # åˆå§‹åŒ–UnitTestä¸“ç”¨Memory
                await unit_test_memory_manager.initialize()

                self.memory_initialized = True

                # é…ç½®Agentä¾èµ–å…³ç³»
                await self._configure_agent_dependencies()

                print("ğŸ§  Orchestrator Memoryç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            else:
                print("âš ï¸ Memoryç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ç»§ç»­ä½¿ç”¨åŸºç¡€åŠŸèƒ½")

    async def _configure_agent_dependencies(self):
        """é…ç½®Agentä¾èµ–å…³ç³»"""
        # å®šä¹‰Agentä¾èµ–å…³ç³»
        agent_dependencies = {
            "FunctionWritingAgent": ["CodePlanningAgent"],
            "TestGenerationAgent": ["FunctionWritingAgent"],
            "UnitTestAgent": ["TestGenerationAgent"],
            "RefactoringAgent": ["UnitTestAgent"],
            "CodeScanningAgent": ["UnitTestAgent", "RefactoringAgent"],
            "ProjectStructureAgent": ["CodeScanningAgent"],
            "ReflectionAgent": ["ProjectStructureAgent"]
        }

        # åªä¿ç•™å½“å‰å·¥ä½œæµä¸­å­˜åœ¨çš„Agentä¾èµ–
        filtered_dependencies = {}
        for agent, deps in agent_dependencies.items():
            if agent in self.participants:
                filtered_deps = [dep for dep in deps if dep in self.participants]
                if filtered_deps:
                    filtered_dependencies[agent] = filtered_deps

        # è®¾ç½®åˆ°é€šä¿¡Memoryä¸­
        agent_communication_memory.agent_dependencies = filtered_dependencies

        print(f"ğŸ”— é…ç½®Agentä¾èµ–å…³ç³»: {len(filtered_dependencies)} ä¸ªä¾èµ–é“¾")

    async def _cleanup_memory_system(self):
        """æ¸…ç†Memoryç³»ç»Ÿ"""
        if self.memory_initialized:
            await cleanup_memory_system()
            print("ğŸ§¹ Orchestrator Memoryç³»ç»Ÿæ¸…ç†å®Œæˆ")

    def _get_current_workflow_stage(self) -> str:
        """è·å–å½“å‰å·¥ä½œæµé˜¶æ®µ"""
        completed_nodes = [name for name, state in self.progress_ledger.node_states.items()
                          if state == NodeState.COMPLETED]

        if not completed_nodes:
            return "initial"
        elif len(completed_nodes) < len(self.participants) // 2:
            return "early"
        elif len(completed_nodes) < len(self.participants):
            return "middle"
        else:
            return "final"

    def _initialize_path_resolver(self):
        """åˆå§‹åŒ–æ™ºèƒ½è·¯å¾„è§£æå™¨"""
        if self.path_resolver is None:
            self.path_resolver = self.task_ledger.get_intelligent_path_resolver()

            # ç”Ÿæˆè·¯å¾„è§£ææŠ¥å‘Š
            report = self.path_resolver.generate_path_report()
            print("ğŸ” æ™ºèƒ½è·¯å¾„è§£æåˆå§‹åŒ–å®Œæˆ")
            print(report)

        return self.path_resolver

    # ================================
    # å¤–å±‚å¾ªç¯ï¼šä»»åŠ¡è§„åˆ’å’Œåˆ†è§£
    # ================================

    async def run_stream(self, task: str):
        """
        è¿è¡Œé«˜çº§è°ƒåº¦çš„å·¥ä½œæµ

        Args:
            task: è¦æ‰§è¡Œçš„ä»»åŠ¡æè¿°

        Yields:
            æ‰§è¡Œè¿‡ç¨‹ä¸­çš„äº‹ä»¶å’Œç»“æœ
        """
        # åˆå§‹åŒ–Memoryç³»ç»Ÿ
        await self._initialize_memory_system()

        self.task_ledger.original_task = task

        try:
            # å¤–å±‚å¾ªç¯ï¼šä»»åŠ¡åˆ†è§£å’Œè®¡åˆ’åˆ¶å®š
            await self._outer_loop_planning(task)

            # å†…å±‚å¾ªç¯ï¼šæ™ºèƒ½æ‰§è¡Œå’Œç›‘æ§
            async for event in self._inner_loop_execution():
                yield event

        finally:
            # æ¸…ç†Memoryç³»ç»Ÿ
            await self._cleanup_memory_system()

    async def _outer_loop_planning(self, task: str):
        """
        å¤–å±‚å¾ªç¯ï¼šä»»åŠ¡åˆ†è§£å’Œè®¡åˆ’åˆ¶å®š

        è¿™ä¸ªæ–¹æ³•è´Ÿè´£ï¼š
        1. è§£æä»»åŠ¡å¹¶ç”ŸæˆåŠ¨æ€æ–‡ä»¶é…ç½®
        2. åˆ†æä»»åŠ¡å¹¶æ”¶é›†ç›¸å…³äº‹å®
        3. åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’
        4. ä¸ºå†…å±‚å¾ªç¯å‡†å¤‡æ‰§è¡Œç¯å¢ƒ
        """
        # è®°å½•ä»»åŠ¡å¼€å§‹
        self.workflow_logger.log_event("info", "å¼€å§‹ä»»åŠ¡è§„åˆ’é˜¶æ®µ")

        # 0. åŠ¨æ€æ–‡ä»¶å‘½åé…ç½®
        self.workflow_logger.log_event("progress", "è§£æä»»åŠ¡å¹¶ç”Ÿæˆæ–‡ä»¶é…ç½®...")
        project_config = await parse_task_and_generate_config(task, self.model_client)

        # è®¾ç½®é¡¹ç›®é…ç½®åˆ°ä»»åŠ¡è´¦æœ¬
        self.task_ledger.set_project_config(
            project_config["project_name"],
            project_config["main_file"],
            project_config["test_file"]
        )

        # è®°å½•ä»»åŠ¡å’Œé¡¹ç›®é…ç½®
        self.workflow_logger.log_task_start(task, {
            "project_name": project_config["project_name"],
            "main_file_path": self.task_ledger.get_file_path('main'),
            "test_file_path": self.task_ledger.get_file_path('test')
        })

        # 1. æ”¶é›†å’Œåˆ†æäº‹å®
        facts_prompt = f"""
        åˆ†æä»¥ä¸‹ä»»åŠ¡å¹¶æ”¶é›†ç›¸å…³äº‹å®ï¼š

        ä»»åŠ¡ï¼š{task}

        é¡¹ç›®é…ç½®ï¼š
        - é¡¹ç›®åç§°ï¼š{project_config['project_name']}
        - ä¸»æ–‡ä»¶è·¯å¾„ï¼š{self.task_ledger.get_file_path('main')}
        - æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼š{self.task_ledger.get_file_path('test')}

        è¯·åˆ—å‡ºï¼š
        1. ä»»åŠ¡ä¸­æ˜ç¡®ç»™å‡ºçš„äº‹å®
        2. éœ€è¦æŸ¥æ‰¾çš„ä¿¡æ¯
        3. éœ€è¦æ¨å¯¼çš„ä¿¡æ¯
        4. åŸºäºç»éªŒçš„æ¨æµ‹

        å¯ç”¨çš„ Agent å›¢é˜Ÿï¼š
        {self._format_team_description()}
        """

        # ä½¿ç”¨ LLM åˆ†æä»»åŠ¡
        response = await self.model_client.create([
            UserMessage(content=facts_prompt, source="orchestrator")
        ])

        facts_analysis = response.content
        self.task_ledger.facts = [facts_analysis]

        self.workflow_logger.log_event("success", "ä»»åŠ¡åˆ†æå®Œæˆ")

        # 2. åˆ¶å®šæ‰§è¡Œè®¡åˆ’
        plan_prompt = f"""
        åŸºäºä»¥ä¸‹ä¿¡æ¯åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ï¼š

        ä»»åŠ¡ï¼š{task}
        äº‹å®åˆ†æï¼š{facts_analysis}

        é¡¹ç›®é…ç½®ï¼š
        - ä¸»æ–‡ä»¶è·¯å¾„ï¼š{self.task_ledger.get_file_path('main')}
        - æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼š{self.task_ledger.get_file_path('test')}

        å¯ç”¨ Agentï¼š
        {self._format_team_description()}

        è¯·åˆ¶å®šä¸€ä¸ªæ­¥éª¤æ¸…æ™°çš„æ‰§è¡Œè®¡åˆ’ï¼Œè¯´æ˜æ¯ä¸ª Agent çš„å…·ä½“ä»»åŠ¡å’Œæ–‡ä»¶è·¯å¾„ã€‚
        """

        response = await self.model_client.create([
            UserMessage(content=plan_prompt, source="orchestrator")
        ])

        plan_content = response.content
        self.task_ledger.plan = [plan_content]

        self.workflow_logger.log_event("success", "æ‰§è¡Œè®¡åˆ’åˆ¶å®šå®Œæˆï¼Œå¼€å§‹å¤šAgentåä½œ")

    def _format_team_description(self) -> str:
        """æ ¼å¼åŒ–å›¢é˜Ÿæè¿°ï¼Œç”¨äºLLMåˆ†æ"""
        descriptions = []
        for name, description in self.task_ledger.agent_capabilities.items():
            descriptions.append(f"{name}: {description}")
        return "\n".join(descriptions)

    # ================================
    # å†…å±‚å¾ªç¯ï¼šæ™ºèƒ½æ‰§è¡Œå’Œç›‘æ§
    # ================================

    async def _inner_loop_execution(self):
        """
        å†…å±‚å¾ªç¯ï¼šæ™ºèƒ½æ‰§è¡Œå’Œç›‘æ§

        è¿™ä¸ªæ–¹æ³•è´Ÿè´£ï¼š
        1. è·å–å¯æ‰§è¡Œçš„èŠ‚ç‚¹
        2. æ™ºèƒ½é€‰æ‹©ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹
        3. ç›‘æ§æ‰§è¡Œç»“æœ
        4. å¤„ç†é”™è¯¯å’Œé‡è¯•é€»è¾‘
        """
        self.workflow_logger.log_event("info", "å¼€å§‹å¤šAgentåä½œæ‰§è¡Œ")

        # è·å–èµ·å§‹èŠ‚ç‚¹
        current_nodes = self._get_source_nodes()
        execution_round = 0

        while current_nodes and self.progress_ledger.stall_count < self.max_stalls:
            execution_round += 1

            # æ™ºèƒ½é€‰æ‹©ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹
            next_node = await self._intelligent_node_selection(current_nodes)

            if not next_node:
                break

            # è®°å½•Agentå¼€å§‹æ‰§è¡Œ
            agent_description = self.task_ledger.agent_capabilities.get(next_node, "æœªçŸ¥åŠŸèƒ½")
            self.workflow_logger.log_agent_start(next_node, agent_description)

            # æ‰§è¡ŒèŠ‚ç‚¹å¹¶ç›‘æ§
            execution_result = await self._execute_node_with_monitoring(next_node)

            # è®°å½•Agentæ‰§è¡Œå®Œæˆ
            success = execution_result.get("success", False)
            output = execution_result.get("analysis", {}).get("message_content", "")
            duration = execution_result.get("execution_time", 0)

            self.workflow_logger.log_agent_complete(next_node, success, output, duration)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°é€‰æ‹© Agent
            if execution_result.get("needs_reselection", False):
                self.workflow_logger.log_event("warning", f"Agent {next_node} éœ€è¦é‡æ–°é€‰æ‹©")
                alternative_nodes = await self._find_alternative_nodes(next_node)
                if alternative_nodes:
                    current_nodes = alternative_nodes
                    self.workflow_logger.log_event("info", f"é€‰æ‹©æ›¿ä»£èŠ‚ç‚¹: {current_nodes}")
                    continue
                else:
                    self.workflow_logger.log_event("warning", "æ— æ›¿ä»£èŠ‚ç‚¹ï¼Œç»§ç»­åŸæµç¨‹")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’
            if await self._should_replan():
                self.workflow_logger.log_event("warning", "æ£€æµ‹åˆ°éœ€è¦é‡æ–°è§„åˆ’ï¼Œé‡æ–°åˆ†æä»»åŠ¡")
                await self._outer_loop_planning(self.task_ledger.original_task)
                current_nodes = self._get_source_nodes()
                continue

            # è·å–ä¸‹ä¸€æ‰¹å¯æ‰§è¡ŒèŠ‚ç‚¹
            current_nodes = await self._get_next_executable_nodes(next_node, execution_result)

            # äº§å‡ºæ‰§è¡Œäº‹ä»¶
            yield TextMessage(
                source=next_node,
                content=f"èŠ‚ç‚¹ {next_node} æ‰§è¡Œå®Œæˆ"
            )

        # è®°å½•å·¥ä½œæµå®Œæˆ
        completed_agents = len([a for a in self.workflow_logger.workflow_data["agents"] if a["status"] == "completed"])
        total_agents = len(self.workflow_logger.workflow_data["agents"])
        success = completed_agents == total_agents

        summary = {
            "total_rounds": execution_round,
            "completed_agents": completed_agents,
            "total_agents": total_agents,
            "success_rate": completed_agents / total_agents if total_agents > 0 else 0
        }

        self.workflow_logger.log_workflow_complete(success, summary)

        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        yield await self._generate_final_result()

    def _get_source_nodes(self) -> List[str]:
        """è·å–å›¾çš„æºèŠ‚ç‚¹ï¼ˆå…¥åº¦ä¸º0çš„èŠ‚ç‚¹ï¼‰"""
        # ç®€åŒ–å®ç°ï¼šè¿”å›ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºèµ·å§‹ç‚¹
        return ["CodePlanningAgent"]

    # ================================
    # æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©å’Œåˆ†æ
    # ================================

    async def _intelligent_node_selection(self, candidate_nodes: List[str]) -> Optional[str]:
        """
        æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©ç®—æ³• - åŸºäº MagenticOne çš„è¿›åº¦è´¦æœ¬åˆ†æ

        Args:
            candidate_nodes: å€™é€‰èŠ‚ç‚¹åˆ—è¡¨

        Returns:
            é€‰ä¸­çš„èŠ‚ç‚¹åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆé€‚çš„èŠ‚ç‚¹åˆ™è¿”å›None
        """
        if not candidate_nodes:
            return None

        # å¦‚æœåªæœ‰ä¸€ä¸ªå€™é€‰ï¼Œä½¿ç”¨è¿›åº¦è´¦æœ¬åˆ†æç”Ÿæˆå…·ä½“æŒ‡ä»¤
        if len(candidate_nodes) == 1:
            selected_node = candidate_nodes[0]
            instruction = await self._generate_specific_instruction(selected_node)
            print(f"ğŸ“‹ æ‰§è¡ŒæŒ‡ä»¤: {instruction}")

            # å­˜å‚¨æŒ‡ä»¤ä¾›åç»­ä½¿ç”¨
            self.progress_ledger.current_active_nodes = {selected_node}
            if not hasattr(self.progress_ledger, 'node_instructions'):
                self.progress_ledger.node_instructions = {}
            self.progress_ledger.node_instructions[selected_node] = instruction

            return selected_node

        # ä½¿ç”¨ MagenticOne é£æ ¼çš„è¿›åº¦è´¦æœ¬åˆ†æ
        progress_analysis = await self._analyze_progress_ledger(candidate_nodes)

        selected_node = progress_analysis.get('next_speaker', {}).get('answer')
        instruction = progress_analysis.get('instruction_or_question', {}).get('answer', '')

        # éªŒè¯é€‰æ‹©æ˜¯å¦æœ‰æ•ˆ
        if selected_node in candidate_nodes:
            print(f"ğŸ“‹ æ‰§è¡ŒæŒ‡ä»¤: {instruction}")

            # å­˜å‚¨æŒ‡ä»¤
            self.progress_ledger.current_active_nodes = {selected_node}
            if not hasattr(self.progress_ledger, 'node_instructions'):
                self.progress_ledger.node_instructions = {}
            self.progress_ledger.node_instructions[selected_node] = instruction

            return selected_node
        else:
            return candidate_nodes[0]

    async def _analyze_progress_ledger(self, candidate_nodes: List[str]) -> Dict[str, Any]:
        """
        åˆ†æè¿›åº¦è´¦æœ¬ - åŸºäº MagenticOne çš„å®ç°

        Args:
            candidate_nodes: å€™é€‰èŠ‚ç‚¹åˆ—è¡¨

        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸
        """
        # æ„å»ºå¯¹è¯å†å²
        conversation_history = self._build_conversation_history()

        # æ„å»ºè¿›åº¦è´¦æœ¬åˆ†ææç¤º
        progress_prompt = f"""
        å›é¡¾æˆ‘ä»¬æ­£åœ¨å¤„ç†çš„ä»¥ä¸‹è¯·æ±‚ï¼š

        {self.task_ledger.original_task}

        æˆ‘ä»¬å·²ç»ç»„å»ºäº†ä»¥ä¸‹å›¢é˜Ÿï¼š

        {self._format_team_description()}

        ä¸ºäº†åœ¨è¯·æ±‚ä¸Šå–å¾—è¿›å±•ï¼Œè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼ŒåŒ…æ‹¬å¿…è¦çš„æ¨ç†ï¼š

        - è¯·æ±‚æ˜¯å¦å·²å®Œå…¨æ»¡è¶³ï¼Ÿï¼ˆå¦‚æœå®Œæˆåˆ™ä¸º Trueï¼Œå¦‚æœåŸå§‹è¯·æ±‚å°šæœªæˆåŠŸä¸”å®Œå…¨è§£å†³åˆ™ä¸º Falseï¼‰
        - æˆ‘ä»¬æ˜¯å¦é™·å…¥äº†é‡å¤ç›¸åŒè¯·æ±‚å’Œ/æˆ–è·å¾—ç›¸åŒå“åº”çš„å¾ªç¯ï¼Ÿå¾ªç¯å¯ä»¥è·¨è¶Šå¤šä¸ªå›åˆ
        - æˆ‘ä»¬æ˜¯å¦åœ¨å–å¾—å‰è¿›è¿›å±•ï¼Ÿï¼ˆå¦‚æœåˆšå¼€å§‹æˆ–æœ€è¿‘çš„æ¶ˆæ¯æ­£åœ¨å¢åŠ ä»·å€¼åˆ™ä¸º Trueã€‚å¦‚æœæœ€è¿‘çš„æ¶ˆæ¯æ˜¾ç¤ºé™·å…¥å¾ªç¯æˆ–å­˜åœ¨é‡å¤§æˆåŠŸéšœç¢çš„è¯æ®åˆ™ä¸º Falseï¼‰
        - è°åº”è¯¥ä¸‹ä¸€ä¸ªå‘è¨€ï¼Ÿï¼ˆä»ä»¥ä¸‹é€‰æ‹©ï¼š{', '.join(candidate_nodes)}ï¼‰
        - ä½ ä¼šç»™è¿™ä¸ªå›¢é˜Ÿæˆå‘˜ä»€ä¹ˆæŒ‡ä»¤æˆ–é—®é¢˜ï¼Ÿï¼ˆç›´æ¥å¯¹ä»–ä»¬è¯´è¯ï¼Œå¹¶åŒ…å«ä»–ä»¬å¯èƒ½éœ€è¦çš„ä»»ä½•å…·ä½“ä¿¡æ¯ï¼‰

        å¯¹è¯å†å²ï¼š
        {conversation_history}

        è¯·æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºç­”æ¡ˆã€‚JSON å¯¹è±¡å¿…é¡»å¯ä»¥ç›´æ¥è§£æã€‚åªè¾“å‡º JSONï¼Œä¸è¦åç¦»æ­¤æ¨¡å¼ï¼š

        {{
           "is_request_satisfied": {{
                "reason": "string",
                "answer": boolean
            }},
            "is_in_loop": {{
                "reason": "string",
                "answer": boolean
            }},
            "is_progress_being_made": {{
                "reason": "string",
                "answer": boolean
            }},
            "next_speaker": {{
                "reason": "string",
                "answer": "string (ä»å€™é€‰ä¸­é€‰æ‹©: {', '.join(candidate_nodes)})"
            }},
            "instruction_or_question": {{
                "reason": "string",
                "answer": "string"
            }}
        }}
        """

        try:
            response = await self.model_client.create([
                UserMessage(content=progress_prompt, source="orchestrator")
            ])

            # è§£æ JSON å“åº”
            from autogen_core.utils import extract_json_from_str

            response_content = response.content.strip()

            # æå– JSON
            json_objects = extract_json_from_str(response_content)
            if json_objects:
                progress_ledger = json_objects[0]
                return progress_ledger
            else:
                return self._get_default_progress_analysis(candidate_nodes)

        except Exception as e:
            return self._get_default_progress_analysis(candidate_nodes)

    def _get_default_progress_analysis(self, candidate_nodes: List[str]) -> Dict[str, Any]:
        """è·å–é»˜è®¤çš„è¿›åº¦åˆ†æç»“æœ"""
        return {
            "is_request_satisfied": {"reason": "é»˜è®¤åˆ†æ", "answer": False},
            "is_in_loop": {"reason": "é»˜è®¤åˆ†æ", "answer": False},
            "is_progress_being_made": {"reason": "é»˜è®¤åˆ†æ", "answer": True},
            "next_speaker": {"reason": "é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå€™é€‰", "answer": candidate_nodes[0]},
            "instruction_or_question": {"reason": "é»˜è®¤æŒ‡ä»¤", "answer": f"è¯·ç»§ç»­æ‰§è¡Œä½ çš„ä¸“ä¸šä»»åŠ¡"}
        }

    def _build_conversation_history(self) -> str:
        """æ„å»ºå¯¹è¯å†å²ï¼Œç”¨äºLLMåˆ†æ"""
        history_lines = []

        # è·å–æœ€è¿‘çš„æ‰§è¡Œå†å²
        recent_history = self.progress_ledger.execution_history[-5:]  # æœ€è¿‘5æ¬¡

        for item in recent_history:
            node = item.get("node", "unknown")
            result = item.get("result", {})
            success = result.get("success", False)
            message_content = result.get("message_content", "")

            history_lines.append(f"{node}: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
            if message_content:
                # æˆªå–æ¶ˆæ¯å†…å®¹çš„å‰100ä¸ªå­—ç¬¦
                preview = message_content[:100] + "..." if len(message_content) > 100 else message_content
                history_lines.append(f"  è¾“å‡º: {preview}")

        return "\n".join(history_lines) if history_lines else "æ— å¯¹è¯å†å²"

    # ================================
    # æ‰§è¡Œç›‘æ§å’Œç»“æœåˆ†æ
    # ================================

    async def _execute_node_with_monitoring(self, node_name: str) -> Dict[str, Any]:
        """
        æ‰§è¡ŒèŠ‚ç‚¹å¹¶ç›‘æ§ç»“æœ

        Args:
            node_name: è¦æ‰§è¡Œçš„èŠ‚ç‚¹åç§°

        Returns:
            åŒ…å«æ‰§è¡Œç»“æœå’Œåˆ†æçš„å­—å…¸
        """
        self.progress_ledger.update_node_state(node_name, NodeState.IN_PROGRESS)

        try:
            agent = self.participants[node_name]

            # æ‰§è¡Œå‰ï¼šå‡†å¤‡Agentä¸Šä¸‹æ–‡å’Œé€šä¿¡ä¿¡æ¯
            if self.memory_initialized:
                await self._prepare_agent_execution(node_name)

            # æ„å»ºå¢å¼ºçš„æç¤º
            enhanced_prompt = await self._build_enhanced_prompt(node_name)

            # æ‰§è¡Œ Agent
            start_time = time.time()

            response = await agent.on_messages(
                [TextMessage(source="user", content=enhanced_prompt)],
                cancellation_token=None
            )

            execution_time = time.time() - start_time

            # åˆ†ææ‰§è¡Œç»“æœ
            result_analysis = await self._analyze_execution_result(node_name, response)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³é‡æ–°é€‰æ‹© Agent
            if not result_analysis["success"] and await self._should_reselect_agent(node_name, result_analysis):
                self.progress_ledger.update_node_state(node_name, NodeState.FAILED)
                self.progress_ledger.stall_count += 1

                # è¿”å›ç‰¹æ®Šæ ‡è®°ï¼Œè¡¨ç¤ºéœ€è¦é‡æ–°é€‰æ‹©
                return {
                    "success": False,
                    "response": response,
                    "analysis": result_analysis,
                    "node": node_name,
                    "execution_time": execution_time,
                    "needs_reselection": True
                }

            if result_analysis["success"]:
                self.progress_ledger.update_node_state(node_name, NodeState.COMPLETED)
                self.progress_ledger.stall_count = max(0, self.progress_ledger.stall_count - 1)
            else:
                self.progress_ledger.update_node_state(node_name, NodeState.FAILED)
                self.progress_ledger.stall_count += 1

            # è®°å½•æ‰§è¡Œç»“æœåˆ°Memoryç³»ç»Ÿ
            if self.memory_initialized:
                try:
                    # æ ‡å‡†Memoryè®°å½•
                    await execution_log_manager.record_execution(
                        agent_name=node_name,
                        task_description=enhanced_prompt[:200] + "..." if len(enhanced_prompt) > 200 else enhanced_prompt,
                        execution_result=result_analysis,
                        success=result_analysis["success"],
                        duration=execution_time,
                        context={
                            "stall_count": self.progress_ledger.stall_count,
                            "workflow_stage": self._get_current_workflow_stage()
                        }
                    )

                    # UnitTestAgentç‰¹æ®Šå¤„ç†ï¼šä¿å­˜å®Œæ•´æµ‹è¯•è¾“å‡º
                    if node_name == "UnitTestAgent":
                        await self._record_complete_unit_test_output(
                            node_name, enhanced_prompt, response, result_analysis, execution_time
                        )

                    # æ‰§è¡Œåï¼šå¤„ç†Agenté€šä¿¡å’Œæ¶ˆæ¯ä¼ é€’
                    await self._process_agent_execution_result(node_name, {
                        "success": result_analysis["success"],
                        "analysis": result_analysis,
                        "execution_time": execution_time
                    })

                except Exception as e:
                    print(f"âš ï¸ Memoryè®°å½•å¤±è´¥: {e}")

            return {
                "success": result_analysis["success"],
                "response": response,
                "analysis": result_analysis,
                "node": node_name,
                "execution_time": execution_time
            }

        except Exception as e:
            self.progress_ledger.update_node_state(node_name, NodeState.FAILED)
            self.progress_ledger.stall_count += 1

            return {
                "success": False,
                "error": str(e),
                "analysis": {
                    "success": False,
                    "failure_reasons": [f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"],
                    "message_content": "",
                    "has_completion_marker": False
                },
                "node": node_name,
                "execution_time": 0
            }

    async def _build_enhanced_prompt(self, node_name: str) -> str:
        """æ„å»ºå¢å¼ºçš„æç¤º - ä½¿ç”¨å…·ä½“æŒ‡ä»¤å’Œé”™è¯¯ä¿¡æ¯"""
        return await OrchestratorHelpers.build_enhanced_prompt(self, node_name)

    async def _generate_specific_instruction(self, node_name: str) -> str:
        """ä¸ºç‰¹å®šèŠ‚ç‚¹ç”Ÿæˆå…·ä½“æ‰§è¡ŒæŒ‡ä»¤ - é›†æˆæ™ºèƒ½è·¯å¾„è§£æ"""
        return await OrchestratorHelpers.generate_specific_instruction(self, node_name)

    async def _check_dependencies(self, node_name: str) -> str:
        """æ£€æŸ¥èŠ‚ç‚¹çš„ä¾èµ–å…³ç³»å’Œå‰ç½®æ¡ä»¶"""
        return await OrchestratorHelpers.check_dependencies(self, node_name)

    def _get_default_instruction(self, node_name: str, dependency_info: str) -> str:
        """è·å–é»˜è®¤æŒ‡ä»¤"""
        return OrchestratorHelpers.get_default_instruction(self, node_name, dependency_info)

    def _format_current_state(self) -> str:
        """æ ¼å¼åŒ–å½“å‰æ‰§è¡ŒçŠ¶æ€"""
        return OrchestratorHelpers.format_current_state(self)

    def _format_node_history(self, node_history: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–èŠ‚ç‚¹å†å²"""
        return OrchestratorHelpers.format_node_history(node_history)

    # ================================
    # ç®€åŒ–çš„è¾…åŠ©æ–¹æ³•å®ç°
    # ================================

    async def _analyze_execution_result(self, node_name: str, response: Response) -> Dict[str, Any]:
        """åˆ†ææ‰§è¡Œç»“æœ - æ£€æŸ¥chat_messageå’Œinner_messages"""
        try:
            # æ”¶é›†æ‰€æœ‰å¯èƒ½åŒ…å«å†…å®¹çš„åœ°æ–¹
            all_content = []

            # 1. æ£€æŸ¥ä¸»è¦çš„chat_messageå†…å®¹
            if response.chat_message:
                all_content.append(response.chat_message.content)

            # 2. æ£€æŸ¥inner_messagesä¸­çš„å†…å®¹
            if hasattr(response, 'inner_messages') and response.inner_messages:
                for inner_msg in response.inner_messages:
                    if hasattr(inner_msg, 'content'):
                        all_content.append(str(inner_msg.content))

            # åˆå¹¶æ‰€æœ‰å†…å®¹è¿›è¡Œåˆ†æ
            combined_content = " ".join(filter(None, all_content))

            # æ£€æŸ¥é¢„æœŸçš„å®Œæˆæ ‡è®°
            completion_markers = {
                "CodePlanningAgent": ["PLANNING_COMPLETE"],
                "FunctionWritingAgent": ["CODING_COMPLETE", "Successfully wrote content"],
                "TestGenerationAgent": ["TESTING_COMPLETE", "Successfully wrote content"],
                "UnitTestAgent": ["UNIT_TESTING_COMPLETE"],
                "RefactoringAgent": ["REFACTORING_COMPLETE"],
                "CodeScanningAgent": ["SCANNING_COMPLETE"],
                "ProjectStructureAgent": ["PROJECT_STRUCTURE_COMPLETE"]
            }

            expected_markers = completion_markers.get(node_name, [])
            has_completion_marker = any(marker in combined_content for marker in expected_markers)

            # è°ƒæ•´æˆåŠŸåˆ¤æ–­é€»è¾‘ - å¦‚æœæœ‰å®Œæˆæ ‡è®°ï¼Œå†…å®¹é•¿åº¦è¦æ±‚å¯ä»¥æ”¾å®½
            if has_completion_marker:
                # ç‰¹æ®Šå¤„ç†ï¼šå•å…ƒæµ‹è¯•Agentéœ€è¦æ£€æŸ¥æµ‹è¯•æ˜¯å¦çœŸæ­£é€šè¿‡
                if node_name == "UnitTestAgent":
                    # æ£€æŸ¥æµ‹è¯•æŠ¥å‘Šæ–‡ä»¶æ˜¯å¦å­˜åœ¨å¤±è´¥
                    try:
                        import json
                        import os
                        report_path = "/Users/jabez/output/test_report.json"
                        if os.path.exists(report_path):
                            with open(report_path, 'r', encoding='utf-8') as f:
                                report_data = json.load(f)

                            failures = report_data.get("summary", {}).get("failures", 0)
                            errors = report_data.get("summary", {}).get("errors", 0)

                            if failures > 0 or errors > 0:
                                success = False
                                failure_reasons.append(f"æµ‹è¯•æŠ¥å‘Šæ˜¾ç¤ºæœ‰ {failures} ä¸ªå¤±è´¥å’Œ {errors} ä¸ªé”™è¯¯")
                            else:
                                success = True
                        else:
                            # å¦‚æœæ²¡æœ‰æŠ¥å‘Šæ–‡ä»¶ï¼Œæ£€æŸ¥è¾“å‡ºå†…å®¹ä¸­çš„æµ‹è¯•ç»“æœ
                            if any(keyword in combined_content.lower() for keyword in ["failed", "error", "assertion"]):
                                success = False
                                failure_reasons.append("è¾“å‡ºå†…å®¹ä¸­æ£€æµ‹åˆ°æµ‹è¯•å¤±è´¥ä¿¡æ¯")
                            else:
                                success = True
                    except Exception as e:
                        # å¦‚æœæ£€æŸ¥æŠ¥å‘Šå¤±è´¥ï¼Œå›é€€åˆ°åŸé€»è¾‘
                        success = True
                else:
                    success = True  # å…¶ä»–Agentæœ‰å®Œæˆæ ‡è®°å°±è®¤ä¸ºæˆåŠŸ
            else:
                success = len(combined_content) > 50  # æ²¡æœ‰å®Œæˆæ ‡è®°éœ€è¦è¶³å¤Ÿçš„å†…å®¹

            failure_reasons = []
            if not has_completion_marker and len(combined_content) <= 50:
                failure_reasons.append(f"ç¼ºå°‘å®Œæˆæ ‡è®°: {expected_markers} ä¸”è¾“å‡ºå†…å®¹è¿‡çŸ­")
            elif not has_completion_marker:
                failure_reasons.append(f"ç¼ºå°‘å®Œæˆæ ‡è®°: {expected_markers}")

            return {
                "success": success,
                "failure_reasons": failure_reasons,
                "message_content": combined_content,
                "has_completion_marker": has_completion_marker
            }

        except Exception as e:
            return {
                "success": False,
                "failure_reasons": [f"åˆ†æå¼‚å¸¸: {str(e)}"],
                "message_content": "",
                "has_completion_marker": False
            }

    async def _should_reselect_agent(self, node_name: str, result_analysis: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°é€‰æ‹©Agent"""
        # ç®€åŒ–å®ç°ï¼šå¦‚æœè¿ç»­å¤±è´¥è¶…è¿‡2æ¬¡ï¼Œåˆ™é‡æ–°é€‰æ‹©
        retry_count = self.progress_ledger.retry_counts.get(node_name, 0)
        return retry_count >= 2 and not result_analysis["success"]

    async def _should_replan(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’"""
        # ç®€åŒ–å®ç°ï¼šå¦‚æœåœæ»æ¬¡æ•°è¿‡å¤šï¼Œåˆ™é‡æ–°è§„åˆ’
        return self.progress_ledger.stall_count >= self.max_stalls

    async def _get_next_executable_nodes(self, current_node: str, execution_result: Dict[str, Any]) -> List[str]:
        """è·å–ä¸‹ä¸€æ‰¹å¯æ‰§è¡ŒèŠ‚ç‚¹ - åŸºäºtest.pyçš„æ™ºèƒ½é“¾è·¯é€‰æ‹©é€»è¾‘"""

        # ç‰¹æ®Šå¤„ç†ï¼šå•å…ƒæµ‹è¯•å¤±è´¥çš„æƒ…å†µ
        if current_node == "UnitTestAgent" and not execution_result["success"]:
            print(f"ğŸ”§ å•å…ƒæµ‹è¯•å¤±è´¥ï¼Œå¯åŠ¨æ™ºèƒ½ä¿®å¤æµç¨‹")

            # æ£€æŸ¥å¤±è´¥åŸå› 
            failure_reasons = execution_result.get("analysis", {}).get("failure_reasons", [])
            message_content = execution_result.get("analysis", {}).get("message_content", "")

            # åˆ†ææ˜¯å¦åŒ…å«æµ‹è¯•é”™è¯¯ä¿¡æ¯
            has_test_errors = any([
                "failed" in message_content.lower(),
                "error" in message_content.lower(),
                "assertion" in message_content.lower(),
                "traceback" in message_content.lower(),
                len(failure_reasons) > 0
            ])

            if has_test_errors:
                print(f"ğŸ“‹ æ£€æµ‹åˆ°æµ‹è¯•é”™è¯¯ï¼Œå°†é”™è¯¯ä¿¡æ¯ä¼ é€’ç»™é‡æ„Agent")
                # å°†é”™è¯¯ä¿¡æ¯å­˜å‚¨åˆ°ä»»åŠ¡è´¦æœ¬ä¸­ï¼Œä¾›é‡æ„Agentä½¿ç”¨
                error_info = {
                    "source": "UnitTestAgent",
                    "errors": failure_reasons,
                    "test_output": message_content,
                    "timestamp": time.time()
                }

                if not hasattr(self.task_ledger, 'error_history'):
                    self.task_ledger.error_history = []
                self.task_ledger.error_history.append(error_info)

                return ["RefactoringAgent"]
            else:
                # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼Œå°è¯•é‡è¯•
                retry_count = self.progress_ledger.retry_counts.get(current_node, 0)
                if retry_count <= self.max_retries:
                    print(f"ğŸ”„ æœªæ£€æµ‹åˆ°æ˜ç¡®é”™è¯¯ï¼Œé‡è¯•å•å…ƒæµ‹è¯•")
                    return [current_node]

        # ç‰¹æ®Šå¤„ç†ï¼šé‡æ„Agentå®Œæˆåï¼Œé‡æ–°è¿›è¡Œå•å…ƒæµ‹è¯•
        elif current_node == "RefactoringAgent" and execution_result["success"]:
            print(f"ğŸ”„ é‡æ„å®Œæˆï¼Œé‡æ–°æ‰§è¡Œå•å…ƒæµ‹è¯•éªŒè¯ä¿®å¤æ•ˆæœ")
            # é‡ç½®UnitTestAgentçš„é‡è¯•è®¡æ•°ï¼Œç»™å®ƒæ–°çš„æœºä¼š
            if "UnitTestAgent" in self.progress_ledger.retry_counts:
                self.progress_ledger.retry_counts["UnitTestAgent"] = 0
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ï¼Œå…è®¸é‡æ–°æ‰§è¡Œ
            self.progress_ledger.node_states["UnitTestAgent"] = NodeState.NOT_STARTED
            return ["UnitTestAgent"]

        # ç‰¹æ®Šå¤„ç†ï¼šå•å…ƒæµ‹è¯•æˆåŠŸåï¼Œè·³è¿‡åæ€Agentï¼Œç›´æ¥è¿›è¡Œä»£ç æ‰«æ
        elif current_node == "UnitTestAgent" and execution_result["success"]:
            print(f"âœ… å•å…ƒæµ‹è¯•é€šè¿‡ï¼Œç»§ç»­åç»­æµç¨‹")
            return ["CodeScanningAgent"]  # è·³è¿‡ReflectionAgent

        # ä¸€èˆ¬å¤±è´¥å¤„ç†ï¼šæ™ºèƒ½é‡è¯•å’Œæ›¿ä»£
        if not execution_result["success"]:
            retry_count = self.progress_ledger.retry_counts.get(current_node, 0)

            if retry_count <= self.max_retries:
                print(f"ğŸ”„ {current_node} æ‰§è¡Œå¤±è´¥ï¼Œå‡†å¤‡é‡è¯• (ç¬¬{retry_count + 1}æ¬¡)")
                return [current_node]  # é‡è¯•å½“å‰èŠ‚ç‚¹
            else:
                print(f"âŒ {current_node} é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œå¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆ")
                # å¯»æ‰¾å¯ä»¥æ›¿ä»£æˆ–ä¿®å¤çš„èŠ‚ç‚¹
                alternative_nodes = await self._find_alternative_nodes(current_node)
                if alternative_nodes:
                    print(f"ğŸ”„ æ‰¾åˆ°æ›¿ä»£èŠ‚ç‚¹: {alternative_nodes}")
                    return alternative_nodes

        # æ­£å¸¸æµç¨‹ï¼šæŒ‰é¢„å®šä¹‰é¡ºåºæ‰§è¡Œ
        normal_flow_sequence = [
            "CodePlanningAgent", "FunctionWritingAgent", "TestGenerationAgent",
            "UnitTestAgent", "CodeScanningAgent", "ProjectStructureAgent"
        ]

        try:
            current_index = normal_flow_sequence.index(current_node)
            if current_index + 1 < len(normal_flow_sequence):
                next_node = normal_flow_sequence[current_index + 1]
                print(f"â¡ï¸ æ­£å¸¸æµç¨‹ï¼š{current_node} -> {next_node}")
                return [next_node]
        except ValueError:
            # å¦‚æœå½“å‰èŠ‚ç‚¹ä¸åœ¨æ­£å¸¸æµç¨‹ä¸­ï¼Œè¿”å›ç©ºåˆ—è¡¨ç»“æŸ
            pass

        return []  # ç»“æŸæµç¨‹

    async def _find_alternative_nodes(self, failed_node: str) -> List[str]:
        """å¯»æ‰¾å¤±è´¥èŠ‚ç‚¹çš„æ›¿ä»£æ–¹æ¡ˆ"""
        alternatives = []

        # æ ¹æ®å¤±è´¥èŠ‚ç‚¹çš„ç±»å‹å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆ
        if failed_node == "FunctionWritingAgent":
            # å¦‚æœç¼–ç å¤±è´¥ï¼Œå¯èƒ½éœ€è¦é‡æ–°è§„åˆ’
            if "CodePlanningAgent" in self.participants:
                alternatives.append("CodePlanningAgent")

        elif failed_node == "TestGenerationAgent":
            # å¦‚æœæµ‹è¯•ç”Ÿæˆå¤±è´¥ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç¼–ç æˆ–ä¿®å¤è·¯å¾„é—®é¢˜
            if "FunctionWritingAgent" in self.participants:
                alternatives.append("FunctionWritingAgent")

        elif failed_node == "UnitTestAgent":
            # å¦‚æœæµ‹è¯•æ‰§è¡Œå¤±è´¥ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç”Ÿæˆæµ‹è¯•æˆ–ä¿®å¤ä»£ç 
            if "TestGenerationAgent" in self.participants:
                alternatives.append("TestGenerationAgent")

        return alternatives

    async def _generate_final_result(self) -> StopMessage:
        """ç”Ÿæˆæœ€ç»ˆç»“æœ"""
        # ç»Ÿè®¡æ‰§è¡Œç»“æœ
        completed_nodes = [node for node, state in self.progress_ledger.node_states.items()
                          if state == NodeState.COMPLETED]
        failed_nodes = [node for node, state in self.progress_ledger.node_states.items()
                       if state == NodeState.FAILED]

        final_message = f"""
ğŸ‰ å¤šAgentåä½œæµç¨‹æ‰§è¡Œå®Œæˆï¼

ğŸ“Š æ‰§è¡Œç»Ÿè®¡ï¼š
âœ… æˆåŠŸå®Œæˆçš„Agent: {len(completed_nodes)}
âŒ æ‰§è¡Œå¤±è´¥çš„Agent: {len(failed_nodes)}
ğŸ”„ æ€»æ‰§è¡Œè½®æ¬¡: {len(self.progress_ledger.execution_history)}

ğŸ“‹ è¯¦ç»†ç»“æœï¼š
æˆåŠŸ: {', '.join(completed_nodes)}
å¤±è´¥: {', '.join(failed_nodes) if failed_nodes else 'æ— '}

ğŸ¯ é¡¹ç›®é…ç½®ï¼š
é¡¹ç›®åç§°: {self.task_ledger.project_config.get('project_name', 'æœªè®¾ç½®')}
ä¸»æ–‡ä»¶: {self.task_ledger.get_file_path('main')}
æµ‹è¯•æ–‡ä»¶: {self.task_ledger.get_file_path('test')}

æ„Ÿè°¢ä½¿ç”¨åŸºäºMCPçš„å¤šé“¾ä»£ç ç”ŸæˆAgentç³»ç»Ÿï¼
        """

        return StopMessage(content=final_message, source="orchestrator")

    # ================================
    # Agenté€šä¿¡å¢å¼ºæ–¹æ³•
    # ================================

    async def _prepare_agent_execution(self, agent_name: str):
        """å‡†å¤‡Agentæ‰§è¡Œï¼šæ”¶é›†ä¸Šä¸‹æ–‡å’Œç›¸å…³ä¿¡æ¯"""
        try:
            # æ›´æ–°Agentä¸Šä¸‹æ–‡ä¸º"starting"
            current_task = self._get_current_task_for_agent(agent_name)
            dependencies = agent_communication_memory.agent_dependencies.get(agent_name, [])

            await agent_communication_memory.update_agent_context(
                agent_name=agent_name,
                current_task=current_task,
                execution_state="starting",
                dependencies=dependencies
            )

            # æ”¶é›†ä¾èµ–Agentçš„è¾“å‡º
            dependency_outputs = await agent_communication_memory.get_dependency_outputs(agent_name)

            # è·å–å‘é€ç»™è¯¥Agentçš„æ¶ˆæ¯
            incoming_messages = await agent_communication_memory.get_messages_for_agent(agent_name, limit=3)

            # æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶å­˜å‚¨åˆ°ä»»åŠ¡è´¦æœ¬ä¸­
            enhanced_context = {
                "dependency_outputs": dependency_outputs,
                "incoming_messages": [
                    f"{msg.from_agent} ({msg.message_type}): {msg.content[:100]}..."
                    for msg in incoming_messages
                ],
                "suggestions": await agent_communication_memory.suggest_next_actions(agent_name)
            }

            # å­˜å‚¨åˆ°ä»»åŠ¡è´¦æœ¬ä¸­
            if not hasattr(self.task_ledger, 'enhanced_contexts'):
                self.task_ledger.enhanced_contexts = {}
            self.task_ledger.enhanced_contexts[agent_name] = enhanced_context

        except Exception as e:
            print(f"âš ï¸ å‡†å¤‡Agentä¸Šä¸‹æ–‡å¤±è´¥: {e}")

    async def _process_agent_execution_result(self, agent_name: str, execution_result: Dict[str, Any]):
        """å¤„ç†æ‰§è¡Œç»“æœï¼šå‘é€æ¶ˆæ¯å’Œæ›´æ–°ä¸Šä¸‹æ–‡"""
        try:
            success = execution_result.get("success", False)
            analysis = execution_result.get("analysis", {})
            message_content = analysis.get("message_content", "")

            # æ›´æ–°Agentä¸Šä¸‹æ–‡
            execution_state = "completed" if success else "failed"
            outputs = {
                "success": success,
                "message_content": message_content,
                "execution_time": execution_result.get("execution_time", 0),
                "analysis": analysis
            }

            await agent_communication_memory.update_agent_context(
                agent_name=agent_name,
                current_task=self._get_current_task_for_agent(agent_name),
                execution_state=execution_state,
                outputs=outputs
            )

            # æ ¹æ®æ‰§è¡Œç»“æœå‘é€ç›¸åº”çš„æ¶ˆæ¯
            await self._send_result_messages(agent_name, execution_result)

            # ç‰¹æ®Šå¤„ç†ï¼šé”™è¯¯ä¼ é€’å’Œæ™ºèƒ½ä¿®å¤
            if not success:
                await self._handle_execution_failure(agent_name, execution_result)
            else:
                await self._handle_execution_success(agent_name, execution_result)

        except Exception as e:
            print(f"âš ï¸ å¤„ç†Agentæ‰§è¡Œç»“æœå¤±è´¥: {e}")

    async def _send_result_messages(self, agent_name: str, execution_result: Dict[str, Any]):
        """æ ¹æ®æ‰§è¡Œç»“æœå‘é€æ¶ˆæ¯ç»™ç›¸å…³Agent"""
        try:
            success = execution_result.get("success", False)
            analysis = execution_result.get("analysis", {})

            # æ‰¾åˆ°ä¾èµ–å½“å‰Agentçš„å…¶ä»–Agent
            dependent_agents = [
                agent for agent, deps in agent_communication_memory.agent_dependencies.items()
                if agent_name in deps and agent in self.participants
            ]

            for dependent_agent in dependent_agents:
                if success:
                    # å‘é€æˆåŠŸç»“æœ
                    await agent_communication_memory.send_message(
                        from_agent=agent_name,
                        to_agent=dependent_agent,
                        message_type="result",
                        content=f"{agent_name} æ‰§è¡ŒæˆåŠŸã€‚è¾“å‡º: {analysis.get('message_content', '')[:200]}",
                        metadata={
                            "execution_time": execution_result.get("execution_time", 0),
                            "success": True
                        }
                    )
                else:
                    # å‘é€é”™è¯¯ä¿¡æ¯
                    failure_reasons = analysis.get("failure_reasons", [])
                    await agent_communication_memory.send_message(
                        from_agent=agent_name,
                        to_agent=dependent_agent,
                        message_type="error",
                        content=f"{agent_name} æ‰§è¡Œå¤±è´¥ã€‚é”™è¯¯: {'; '.join(failure_reasons)}",
                        metadata={
                            "failure_reasons": failure_reasons,
                            "success": False
                        }
                    )
        except Exception as e:
            print(f"âš ï¸ å‘é€ç»“æœæ¶ˆæ¯å¤±è´¥: {e}")

    def _get_current_task_for_agent(self, agent_name: str) -> str:
        """è·å–Agentçš„å½“å‰ä»»åŠ¡æè¿°"""
        task_mapping = {
            "CodePlanningAgent": "åˆ¶å®šä»£ç å®ç°è®¡åˆ’",
            "FunctionWritingAgent": "ç¼–å†™å‡½æ•°ä»£ç ",
            "TestGenerationAgent": "ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹",
            "UnitTestAgent": "æ‰§è¡Œå•å…ƒæµ‹è¯•",
            "RefactoringAgent": "ä¿®å¤ä»£ç é—®é¢˜",
            "CodeScanningAgent": "æ‰§è¡Œä»£ç æ‰«æ",
            "ProjectStructureAgent": "æ•´ç†é¡¹ç›®ç»“æ„",
            "ReflectionAgent": "æ€»ç»“å¼€å‘è¿‡ç¨‹"
        }
        return task_mapping.get(agent_name, "æ‰§è¡Œä¸“ä¸šä»»åŠ¡")

    async def _handle_execution_failure(self, agent_name: str, execution_result: Dict[str, Any]):
        """å¤„ç†æ‰§è¡Œå¤±è´¥çš„æƒ…å†µ"""
        try:
            analysis = execution_result.get("analysis", {})
            failure_reasons = analysis.get("failure_reasons", [])
            message_content = analysis.get("message_content", "")

            # ç‰¹æ®Šå¤„ç†ï¼šUnitTestAgentå¤±è´¥ â†’ RefactoringAgent
            if agent_name == "UnitTestAgent" and "RefactoringAgent" in self.participants:
                # è·å–å®Œæ•´çš„æµ‹è¯•ä¿¡æ¯
                detailed_test_info = await unit_test_memory_manager.get_detailed_test_info_for_refactoring("UnitTestAgent")

                # å‘é€è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                await agent_communication_memory.send_message(
                    from_agent="UnitTestAgent",
                    to_agent="RefactoringAgent",
                    message_type="error",
                    content=f"å•å…ƒæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤ã€‚é”™è¯¯è¯¦æƒ…: {message_content}",
                    metadata={
                        "failure_reasons": failure_reasons,
                        "test_output": message_content,
                        "priority": "high",
                        "detailed_test_info": detailed_test_info
                    }
                )

                # å‘é€å®Œæ•´çš„æµ‹è¯•ä¸Šä¸‹æ–‡ä¿¡æ¯
                if detailed_test_info:
                    context_content = f"""
æµ‹è¯•ç¯å¢ƒå’Œä»£ç ä¸Šä¸‹æ–‡ä¿¡æ¯: {self._get_test_context()}

=== å®Œæ•´æµ‹è¯•è¾“å‡º ===
{detailed_test_info.get('complete_raw_output', '')[:1000]}...

=== è§£æçš„å¤±è´¥ä¿¡æ¯ ===
{detailed_test_info.get('parsed_failures', [])}

=== æ™ºèƒ½ä¿®å¤å»ºè®® ===
{chr(10).join(detailed_test_info.get('detailed_recommendations', []))}

=== é”™è¯¯æ¨¡å¼åˆ†æ ===
{detailed_test_info.get('error_patterns', [])}
                    """.strip()
                else:
                    context_content = f"æµ‹è¯•ç¯å¢ƒå’Œä»£ç ä¸Šä¸‹æ–‡ä¿¡æ¯: {self._get_test_context()}"

                await agent_communication_memory.send_message(
                    from_agent="UnitTestAgent",
                    to_agent="RefactoringAgent",
                    message_type="context",
                    content=context_content,
                    metadata={
                        "context_type": "detailed_test_environment",
                        "has_detailed_info": bool(detailed_test_info)
                    }
                )
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ‰§è¡Œå¤±è´¥å¤±è´¥: {e}")

    async def _handle_execution_success(self, agent_name: str, execution_result: Dict[str, Any]):
        """å¤„ç†æ‰§è¡ŒæˆåŠŸçš„æƒ…å†µ"""
        try:
            analysis = execution_result.get("analysis", {})
            message_content = analysis.get("message_content", "")

            # ç‰¹æ®Šå¤„ç†ï¼šRefactoringAgentæˆåŠŸ â†’ UnitTestAgent
            if agent_name == "RefactoringAgent" and "UnitTestAgent" in self.participants:
                await agent_communication_memory.send_message(
                    from_agent="RefactoringAgent",
                    to_agent="UnitTestAgent",
                    message_type="context",
                    content=f"ä»£ç ä¿®å¤å®Œæˆã€‚ä¿®å¤å†…å®¹: {message_content}",
                    metadata={
                        "context_type": "code_fix",
                        "priority": "high"
                    }
                )

            # CodeScanningAgentæˆåŠŸ â†’ ProjectStructureAgent
            elif agent_name == "CodeScanningAgent" and "ProjectStructureAgent" in self.participants:
                await agent_communication_memory.send_message(
                    from_agent="CodeScanningAgent",
                    to_agent="ProjectStructureAgent",
                    message_type="result",
                    content=f"ä»£ç æ‰«æå®Œæˆã€‚æ‰«æç»“æœ: {message_content}",
                    metadata={
                        "scan_results": analysis,
                        "context_type": "scan_report"
                    }
                )
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ‰§è¡ŒæˆåŠŸå¤±è´¥: {e}")

    def _get_test_context(self) -> str:
        """è·å–æµ‹è¯•ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        test_file_path = getattr(self.task_ledger, 'test_file_path', 'unknown')
        main_file_path = getattr(self.task_ledger, 'main_file_path', 'unknown')
        return f"æµ‹è¯•æ–‡ä»¶: {test_file_path}, ä¸»æ–‡ä»¶: {main_file_path}"

    async def _record_complete_unit_test_output(self,
                                              agent_name: str,
                                              task_description: str,
                                              raw_response: str,
                                              result_analysis: Dict[str, Any],
                                              execution_time: float):
        """è®°å½•UnitTestAgentçš„å®Œæ•´è¾“å‡º"""
        try:
            # æå–æµ‹è¯•æ–‡ä»¶ä¿¡æ¯
            test_files = self._extract_test_files_from_response(raw_response)

            # æå–æµ‹è¯•æŠ¥å‘Šä¿¡æ¯
            test_reports = self._extract_test_reports_from_response(raw_response)

            # è®°å½•åˆ°UnitTestä¸“ç”¨Memory
            await unit_test_memory_manager.record_complete_test_execution(
                agent_name=agent_name,
                task_description=task_description,
                raw_output=raw_response,
                execution_result=result_analysis,
                success=result_analysis["success"],
                duration=execution_time,
                test_files=test_files,
                test_reports=test_reports
            )

            print(f"ğŸ§ª UnitTestAgentå®Œæ•´è¾“å‡ºå·²ä¿å­˜åˆ°ä¸“ç”¨Memory")

        except Exception as e:
            print(f"âš ï¸ è®°å½•UnitTestAgentå®Œæ•´è¾“å‡ºå¤±è´¥: {e}")

    def _extract_test_files_from_response(self, response: str) -> List[str]:
        """ä»å“åº”ä¸­æå–æµ‹è¯•æ–‡ä»¶è·¯å¾„"""
        test_files = []
        lines = response.split('\n')

        for line in lines:
            # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶è·¯å¾„
            if "test_" in line and ".py" in line:
                # æå–æ–‡ä»¶è·¯å¾„
                import re
                path_match = re.search(r'[/\\]?[\w/\\]+test_[\w_]+\.py', line)
                if path_match:
                    test_files.append(path_match.group(0))

        return list(set(test_files))  # å»é‡

    def _extract_test_reports_from_response(self, response: str) -> Dict[str, Any]:
        """ä»å“åº”ä¸­æå–æµ‹è¯•æŠ¥å‘Šä¿¡æ¯"""
        reports = {}

        # æŸ¥æ‰¾JSONæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š
        import re
        json_pattern = r'\{[^{}]*"test_files"[^{}]*\}'
        json_matches = re.findall(json_pattern, response, re.DOTALL)

        for i, json_str in enumerate(json_matches):
            try:
                import json
                report_data = json.loads(json_str)
                reports[f"report_{i+1}"] = report_data
            except:
                continue

        # æŸ¥æ‰¾Markdownæ ¼å¼çš„æŠ¥å‘Šè·¯å¾„
        md_pattern = r'test_report\.md'
        if re.search(md_pattern, response):
            reports["markdown_report"] = "test_report.md"

        return reports
